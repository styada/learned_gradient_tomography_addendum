{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Partially learned gradient descent scheme for ellipses.\n","\n","    The code implements a partially learned gradient descent scheme for ellipses using TensorFlow and\n","    ODL, with the ability to generate random data and validate the results.\n","    \n","    :param validation: The `validation` parameter in the code is used to determine whether to generate a\n","    set of random data for validation purposes. When `validation` is set to `True`, the code generates\n","    data for validation, and when it is set to `False`, the code generates random data for training.\n","    This parameter, defaults to False (optional)\n","    :return: The code snippet provided is a partially learned gradient descent scheme for ellipses using\n","    TensorFlow and ODL (Operator Discretization Library). The code defines a neural network model that\n","    iteratively updates an input image to minimize the difference between the reconstructed image and\n","    the ground truth image."]},{"cell_type":"markdown","metadata":{},"source":["### The Imports"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /Users/saityada/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}],"source":["import tensorflow.compat.v1 as tf\n","\n","import numpy as np\n","import odl\n","import odl.contrib.tensorflow\n","from util import random_phantom, conv2d\n","\n","tf.disable_v2_behavior()"]},{"cell_type":"markdown","metadata":{},"source":["### Variable declaration"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["sess = tf.InteractiveSession()\n","\n","# Create ODL data structures\n","size = 128\n","space = odl.uniform_discr([-64, -64], [64, 64], [size, size],\n","                        dtype='float32')\n","\n","# TODO: limited angles approach\n","geometry = odl.tomo.parallel_beam_geometry(space, num_angles=30)\n","operator = odl.tomo.RayTransform(space, geometry)\n","pseudoinverse = odl.tomo.fbp_op(operator)\n","\n","# Ensure operator has fixed operator norm for scale invariance\n","opnorm = odl.power_method_opnorm(operator)\n","operator = (1 / opnorm) * operator\n","pseudoinverse = pseudoinverse * opnorm\n","\n","# Create tensorflow layer from odl operator\n","odl_op_layer = odl.contrib.tensorflow.as_tensorflow_layer(operator,\n","                                                        'RayTransform')\n","odl_op_layer_adjoint = odl.contrib.tensorflow.as_tensorflow_layer(operator.adjoint,\n","                                                                'RayTransformAdjoint')\n","\n","partial0 = odl.PartialDerivative(space, axis=0)\n","partial1 = odl.PartialDerivative(space, axis=1)\n","\n","# TODO: Different Regularization methods\n","odl_op_regularizer = odl.contrib.tensorflow.as_tensorflow_layer(partial0.adjoint * partial0 +\n","                                                                partial1.adjoint * partial1,\n","                                                                'Regularizer')\n","\n","# User selected paramters\n","n_data = 20\n","n_memory = 5\n","n_iter = 10"]},{"cell_type":"markdown","metadata":{},"source":["### Data Generation"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def generate_data(validation=False):\n","    \"\"\"Generate a set of random data.\"\"\"\n","    n_iter = 1 if validation else n_data\n","\n","    x_arr = np.empty((n_iter, space.shape[0], space.shape[1], 1), dtype='float32')\n","    y_arr = np.empty((n_iter, operator.range.shape[0], operator.range.shape[1], 1), dtype='float32')\n","    x_true_arr = np.empty((n_iter, space.shape[0], space.shape[1], 1), dtype='float32')\n","\n","    for i in range(n_iter):\n","        if validation:\n","            phantom = odl.phantom.shepp_logan(space, True)\n","        else:\n","            phantom = random_phantom(space)\n","        data = operator(phantom)\n","        noisy_data = data + odl.phantom.white_noise(operator.range) * np.mean(np.abs(data)) * 0.05\n","        fbp = pseudoinverse(noisy_data)\n","\n","        x_arr[i, ..., 0] = fbp\n","        x_true_arr[i, ..., 0] = phantom\n","        y_arr[i, ..., 0] = noisy_data\n","\n","    return x_arr, y_arr, x_true_arr\n"]},{"cell_type":"markdown","metadata":{},"source":["### Placeholders"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["with tf.name_scope('placeholders'):\n","    x_0 = tf.placeholder(tf.float32, shape=[None, size, size, 1], name=\"x_0\")\n","    x_true = tf.placeholder(tf.float32, shape=[None, size, size, 1], name=\"x_true\")\n","    y = tf.placeholder(tf.float32, shape=[None, operator.range.shape[0], operator.range.shape[1], 1], name=\"y\")\n","\n","    s = tf.fill([tf.shape(x_0)[0], size, size, n_memory], np.float32(0.0), name=\"s\")\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["create_parameters = False"]},{"cell_type":"markdown","metadata":{},"source":["### Creating/Loading layers"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["with tf.name_scope('variable_definitions'):\n","    if create_parameters:\n","        # Parameters if the network should be re-trained\n","        w1 = tf.get_variable(\"w1\", shape=[3, 3, n_memory + 3, 32],\n","            initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=False, dtype=tf.float32))\n","        b1 = tf.Variable(tf.constant(0.01, shape=[1, 1, 1, 32]), name='b1')\n","\n","        w2 = tf.get_variable(\"w2\", shape=[3, 3, 32, 32],\n","            initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=False, dtype=tf.float32))\n","        b2 = tf.Variable(tf.constant(0.01, shape=[1, 1, 1, 32]), name='b2')\n","\n","        w3 = tf.get_variable(\"w3\", shape=[3, 3, 32, n_memory + 1],\n","            initializer=tf.contrib.layers.xavier_initializer_conv2d(uniform=False, dtype=tf.float32))\n","        b3 = tf.Variable(tf.constant(0.00, shape=[1, 1, 1, n_memory + 1]), name='b3')\n","    else:\n","        # If trained network is available, re-use as starting guess\n","        ld = np.load(\"partially_learned_gradient_descent_parameters.npz\")\n","\n","        w1 = tf.Variable(tf.constant(ld['w1']), name='w1')\n","        b1 = tf.Variable(tf.constant(ld['b1']), name='b1')\n","\n","        w2 = tf.Variable(tf.constant(ld['w2']), name='w2')\n","        b2 = tf.Variable(tf.constant(ld['b2']), name='b2')\n","\n","    # TODO: Adding more layers to the neural network\n","        w3 = tf.Variable(tf.constant(ld['w3']), name='w3')\n","        b3 = tf.Variable(tf.constant(ld['b3']), name='b3')\n"]},{"cell_type":"markdown","metadata":{},"source":["## Main Iterative Scheme/Algorithm from Paper"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /Users/saityada/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/odl/contrib/tensorflow/layer.py:103: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n"]}],"source":["# Implementation of the iterative scheme\n","x_values = [x_0]\n","x = x_0\n","for i in range(n_iter):\n","    with tf.name_scope(f'iterate_{i}'):\n","        gradx = odl_op_layer_adjoint(odl_op_layer(x) - y)\n","        gradreg = odl_op_regularizer(x)\n","\n","        update = tf.concat([x, gradx, gradreg, s], axis=3)\n","\n","        # TODO: look into different activation relu\n","        update = tf.nn.relu(conv2d(update, w1) + b1)\n","        update = tf.nn.relu(conv2d(update, w2) + b2)\n","\n","        update = conv2d(update, w3) + b3\n","\n","        s = tf.nn.relu(update[..., 1:])\n","        dx = update[..., 0:1]\n","\n","        x = x + dx\n","        x_values.append(x)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Loss Function"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["with tf.name_scope('loss'):\n","    loss = tf.reduce_mean(tf.reduce_sum((x - x_true) ** 2, axis=(1, 2)))\n"]},{"cell_type":"markdown","metadata":{},"source":["### Optimizer"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From /Users/saityada/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/training/rmsprop.py:188: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"]}],"source":["with tf.name_scope('optimizer'):\n","    # Learning rate\n","    global_step = tf.Variable(0, trainable=False)\n","    starter_learning_rate = 1e-3\n","    learning_rate = tf.train.inverse_time_decay(starter_learning_rate,\n","                                                global_step=global_step,\n","                                                decay_rate=1.0,\n","                                                decay_steps=500,\n","                                                staircase=True,\n","                                                name='learning_rate')\n","\n","    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)\n"]},{"cell_type":"markdown","metadata":{},"source":["### Tying it all together"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-17 20:13:20.539615: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n"]}],"source":["# Initialize all TF variables\n","tf.global_variables_initializer().run()\n","\n","# Solve with an ODL callback to see what happens in real time\n","callback = odl.solvers.CallbackShow(clim=[0.1, 0.4])\n","\n","# Generate validation data\n","x_arr_validate, y_arr_validate, x_true_arr_validate = generate_data(validation=True)\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["train_new_network = True\n","save_interval = 100"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved up to iteration 100\n","Saved up to iteration 200\n","Saved up to iteration 300\n","Saved up to iteration 400\n","Saved up to iteration 500\n","Saved up to iteration 600\n","Saved up to iteration 700\n","Saved up to iteration 800\n","Saved up to iteration 900\n","Saved up to iteration 1000\n"]}],"source":["import pandas as pd\n","if train_new_network:\n","    # Train the network\n","    n_train = 1000\n","    validation_losses = []\n","    for i in range(0, n_train):\n","        x_arr, y_arr, x_true_arr = generate_data()\n","\n","        _, loss_training = sess.run([optimizer, loss],\n","                                feed_dict={x_0: x_arr,\n","                                            x_true: x_true_arr,\n","                                            y: y_arr})\n","\n","        # Validate on shepp-logan\n","        x_values_result, loss_result = sess.run([x_values, loss],\n","                    feed_dict={x_0: x_arr_validate,\n","                                x_true: x_true_arr_validate,\n","                                y: y_arr_validate})\n","\n","        # print('iter={}, validation loss={}'.format(i, loss_result))\n","        validation_losses.append({\n","                'iteration': i,\n","                'validation_losses' : loss_result\n","            })\n","            # callback((space ** (n_iter + 1)).element(\n","                # [xv.squeeze() for xv in x_values_result]))\n","        if (i + 1) % save_interval == 0 or (i + 1) == n_train:\n","            df = pd.DataFrame(validation_losses)\n","            with pd.ExcelWriter(\"../gradient_validation_losses.xlsx\", mode='a', if_sheet_exists='overlay') as writer:\n","                df.to_excel(writer, index=False, header=True)  # Write header only once\n","            print(f'Saved up to iteration {i + 1}')\n","else:\n","    # Validate on shepp-logan\n","    x_values_result, loss_result = sess.run([x_values, loss],\n","                feed_dict={x_0: x_arr_validate,\n","                                x_true: x_true_arr_validate,\n","                                y: y_arr_validate\n","                            })\n","\n","    print('validation loss={}'.format(loss_result))\n","\n","    callback((space ** (n_iter + 1)).element(\n","        [xv.squeeze() for xv in x_values_result]))"]}],"metadata":{"kernelspec":{"display_name":"illpropinverse","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"}},"nbformat":4,"nbformat_minor":2}
