{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partially learned gradient descent without gradients as input.\n",
    "    This Python script implements a partially learned gradient descent algorithm using TensorFlow for\n",
    "    iterative image reconstruction from projection data.\n",
    "    \n",
    "    :param validation: The `validation` parameter in the code is used to determine whether to generate a\n",
    "    set of random data for validation purposes or for training purposes. When `validation` is set to\n",
    "    `True`, the code generates data for validation by using the Shepp-Logan phantom in the ODL library.\n",
    "    This, defaults to False (optional)\n",
    "    :return: The code is a TensorFlow implementation of a partially learned\n",
    "    gradient descent algorithm without gradients as input for solving an inverse problem in computed\n",
    "    tomography. The code includes the definition of placeholders, variable definitions, an iterative\n",
    "    scheme, loss calculation, optimizer setup, and training/validation data generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/saityada/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import odl\n",
    "import odl.contrib.tensorflow\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Create ODL data structures\n",
    "size = 128\n",
    "space = odl.uniform_discr([-64, -64], [64, 64], [size, size], dtype='float32')\n",
    "\n",
    "geometry = odl.tomo.parallel_beam_geometry(space, num_angles=30)\n",
    "operator = odl.tomo.RayTransform(space, geometry)\n",
    "pseudoinverse = odl.tomo.fbp_op(operator)\n",
    "\n",
    "# Ensure operator has fixed operator norm for scale invariance\n",
    "opnorm = odl.power_method_opnorm(operator)\n",
    "operator = (1 / opnorm) * operator\n",
    "pseudoinverse = pseudoinverse * opnorm\n",
    "\n",
    "# User selected paramters\n",
    "n_data = 20\n",
    "n_memory = 5\n",
    "n_iter = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_ellipse():\n",
    "    return ((np.random.rand() - 0.3) * np.random.exponential(0.3),\n",
    "            np.random.exponential() * 0.2, np.random.exponential() * 0.2,\n",
    "            np.random.rand() - 0.5, np.random.rand() - 0.5,\n",
    "            np.random.rand() * 2 * np.pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_phantom(spc):\n",
    "    n = np.random.poisson(100)\n",
    "    ellipses = [random_ellipse() for _ in range(n)]\n",
    "    return odl.phantom.ellipsoid_phantom(spc, ellipses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, stride=(1, 1)):\n",
    "    \"\"\"\n",
    "    The conv2d function performs a 2D convolution operation using TensorFlow with specified stride and\n",
    "    padding.\n",
    "    \n",
    "    :param x: The parameter `x` in the `conv2d` function represents the input tensor to the\n",
    "    convolutional layer. This tensor typically contains the input data or features that are being\n",
    "    processed through the convolution operation\n",
    "    :param W: The parameter `W` in the `conv2d` function represents the filter weights for the\n",
    "    convolution operation. These weights are learned during the training process of a neural network.\n",
    "    The filter weights determine how the convolution operation is applied to the input data `x` to\n",
    "    extract features\n",
    "    :param stride: The `stride` parameter in the `conv2d` function represents the stride length for\n",
    "    moving the convolutional filter/kernel across the input tensor `x`\n",
    "    :return: The function `conv2d` is returning the result of applying a 2D convolution operation using\n",
    "    the input `x`, filter `W`, and the specified stride. The output of the convolution operation is\n",
    "    returned.\n",
    "    \"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride[0], stride[1], 1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(validation=False):\n",
    "    \"\"\"Generate a set of random data.\"\"\"\n",
    "    n_iter = 1 if validation else n_data\n",
    "\n",
    "    x_arr = np.empty((n_iter, space.shape[0], space.shape[1], 1), dtype='float32')\n",
    "    y_arr = np.empty((n_iter, operator.range.shape[0], operator.range.shape[1], 1), dtype='float32')\n",
    "    x_true_arr = np.empty((n_iter, space.shape[0], space.shape[1], 1), dtype='float32')\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        if validation:\n",
    "            phantom = odl.phantom.shepp_logan(space, True)\n",
    "        else:\n",
    "            phantom = random_phantom(space)\n",
    "\n",
    "        data = operator(phantom)\n",
    "        noisy_data = data + odl.phantom.white_noise(operator.range) * np.mean(np.abs(data)) * 0.05\n",
    "        fbp = pseudoinverse(noisy_data)\n",
    "\n",
    "        x_arr[i, ..., 0] = fbp\n",
    "        x_true_arr[i, ..., 0] = phantom\n",
    "        y_arr[i, ..., 0] = noisy_data\n",
    "\n",
    "    return x_arr, y_arr, x_true_arr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('placeholders'):\n",
    "    x_0 = tf.placeholder(tf.float32, shape=[None, size, size, 1], name=\"x_0\")\n",
    "    x_true = tf.placeholder(tf.float32, shape=[None, size, size, 1], name=\"x_true\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, operator.range.shape[0], operator.range.shape[1], 1], name=\"y\")\n",
    "\n",
    "    s = tf.fill([tf.shape(x_0)[0], size, size, n_memory], np.float32(0.0), name=\"s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_new_parameters_for_network_retraining = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('variable_definitions'):\n",
    "    if create_new_parameters_for_network_retraining:\n",
    "        # Parameters if the network should be re-trained\n",
    "        w1 = tf.get_variable(\n",
    "            \"w1\", shape=[3, 3, n_memory + 1, 32],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)  # or glorot_uniform\n",
    "        )\n",
    "        b1 = tf.Variable(tf.constant_initializer(0.01), shape=[1, 1, 1, 32], name='b1')\n",
    "\n",
    "        w2 = tf.get_variable(\n",
    "            \"w2\", shape=[3, 3, 32, 32],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)\n",
    "        )\n",
    "        b2 = tf.Variable(tf.constant_initializer(0.01), shape=[1, 1, 1, 32], name='b2')\n",
    "\n",
    "        w3 = tf.get_variable(\n",
    "            \"w3\", shape=[3, 3, 32, n_memory + 1],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)\n",
    "        )\n",
    "        b3 = tf.Variable(tf.constant_initializer(0.0), shape=[1, 1, 1, n_memory + 1], name='b3')\n",
    "    else:\n",
    "        # If trained network is available, re-use as starting guess\n",
    "        ld = np.load('code/partially_learned_gradient_descent_no_gradients_parameters.npz')\n",
    "\n",
    "        w1 = tf.Variable(ld['w1'], name='w1')\n",
    "        b1 = tf.Variable(ld['b1'], name='b1')\n",
    "\n",
    "        w2 = tf.Variable(ld['w2'], name='w2')\n",
    "        b2 = tf.Variable(ld['b2'], name='b2')\n",
    "\n",
    "        w3 = tf.Variable(ld['w3'], name='w3')\n",
    "        b3 = tf.Variable(ld['b3'], name='b3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('variable_definitions'):\n",
    "    if create_new_parameters_for_network_retraining:\n",
    "        # Parameters if the network should be re-trained\n",
    "        w1 = tf.get_variable(\"w1\", shape=[3, 3, n_memory + 1, 32],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)  # or glorot_uniform\n",
    "        )\n",
    "        b1 = tf.Variable(tf.constant(0.01, shape=[1, 1, 1, 32]), name='b1')\n",
    "\n",
    "        w2 = tf.get_variable(\"w2\", shape=[3, 3, 32, 32],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)  # or glorot_uniform\n",
    "        )\n",
    "        b2 = tf.Variable(tf.constant(0.01, shape=[1, 1, 1, 32]), name='b2')\n",
    "\n",
    "        w3 = tf.get_variable(\"w3\", shape=[3, 3, 32, n_memory + 1],\n",
    "            initializer=tf.compat.v1.keras.initializers.glorot_normal(dtype=tf.float32)  # or glorot_uniform\n",
    "        )\n",
    "        b3 = tf.Variable(tf.constant(0.00, shape=[1, 1, 1, n_memory + 1]), name='b3')\n",
    "    else:\n",
    "        # If trained network is available, re-use as starting guess\n",
    "        ld = np.load('code/partially_learned_gradient_descent_no_gradients_parameters.npz')\n",
    "\n",
    "        w1 = tf.Variable(tf.constant(ld['w1']), name='w1')\n",
    "        b1 = tf.Variable(tf.constant(ld['b1']), name='b1')\n",
    "\n",
    "        w2 = tf.Variable(tf.constant(ld['w2']), name='w2')\n",
    "        b2 = tf.Variable(tf.constant(ld['b2']), name='b2')\n",
    "\n",
    "        w3 = tf.Variable(tf.constant(ld['w3']), name='w3')\n",
    "        b3 = tf.Variable(tf.constant(ld['b3']), name='b3')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the iterative scheme\n",
    "x_values = [x_0]\n",
    "x = x_0\n",
    "for i in range(n_iter):\n",
    "    with tf.name_scope('iterate_{}'.format(i)):\n",
    "        update = tf.concat([x, s], axis=3)\n",
    "\n",
    "        update = tf.nn.relu(conv2d(update, w1) + b1)\n",
    "        update = tf.nn.relu(conv2d(update, w2) + b2)\n",
    "\n",
    "        update = conv2d(update, w3) + b3\n",
    "\n",
    "        s = tf.nn.relu(update[..., 1:])\n",
    "        dx = update[..., 0:1]\n",
    "\n",
    "        x = x + dx\n",
    "        x_values.append(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: Tensor(\"iterate_9/add_3:0\", shape=(?, 128, 128, 1), dtype=float32)\n",
      "x_values: [<tf.Tensor 'placeholders/x_0:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_0/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_1/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_2/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_3/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_4/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_5/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_6/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_7/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_8/add_3:0' shape=(?, 128, 128, 1) dtype=float32>, <tf.Tensor 'iterate_9/add_3:0' shape=(?, 128, 128, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x: {x}\")\n",
    "print(f\"x_values: {x_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum((x - x_true) ** 2, axis=(1, 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/saityada/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/training/rmsprop.py:188: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    # Learning rate\n",
    "    global_step = tf.Variable(0, trainable=False)\n",
    "    starter_learning_rate = 1e-3\n",
    "    learning_rate = tf.train.inverse_time_decay(starter_learning_rate,\n",
    "                                                global_step=global_step,\n",
    "                                                decay_rate=1.0,\n",
    "                                                decay_steps=500,\n",
    "                                                staircase=True,\n",
    "                                                name='learning_rate')\n",
    "\n",
    "    optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimizer: name: \"optimizer/RMSProp\"\n",
      "op: \"AssignAdd\"\n",
      "input: \"optimizer/Variable\"\n",
      "input: \"optimizer/RMSProp/value\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_INT32\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_class\"\n",
      "  value {\n",
      "    list {\n",
      "      s: \"loc:@optimizer/Variable\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"use_locking\"\n",
      "  value {\n",
      "    b: false\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize all TF variables\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "# Solve with an ODL callback to see what happens in real time\n",
    "callback = odl.solvers.CallbackShow(clim=[0.1, 0.4])\n",
    "\n",
    "# Generate validation data\n",
    "x_arr_validate, y_arr_validate, x_true_arr_validate = generate_data(validation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_arr_validate: [[[[-0.10140869]\n",
      "   [-0.25602037]\n",
      "   [-0.3885349 ]\n",
      "   ..., \n",
      "   [-0.5222962 ]\n",
      "   [-0.20758657]\n",
      "   [-0.02674543]]\n",
      "\n",
      "  [[ 0.20892316]\n",
      "   [-0.07333555]\n",
      "   [-0.29943323]\n",
      "   ..., \n",
      "   [-0.3590231 ]\n",
      "   [ 0.00687671]\n",
      "   [ 0.2180908 ]]\n",
      "\n",
      "  [[ 0.10738922]\n",
      "   [ 0.23372526]\n",
      "   [-0.02825779]\n",
      "   ..., \n",
      "   [ 0.2516903 ]\n",
      "   [ 0.2396455 ]\n",
      "   [-0.08490887]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.1335358 ]\n",
      "   [ 0.14565633]\n",
      "   [ 0.07794141]\n",
      "   ..., \n",
      "   [ 0.16508862]\n",
      "   [ 0.18416016]\n",
      "   [-0.1588907 ]]\n",
      "\n",
      "  [[ 0.02378147]\n",
      "   [-0.14154857]\n",
      "   [-0.11896355]\n",
      "   ..., \n",
      "   [-0.34875485]\n",
      "   [-0.00724699]\n",
      "   [ 0.2507021 ]]\n",
      "\n",
      "  [[-0.01584784]\n",
      "   [-0.28331408]\n",
      "   [-0.3335182 ]\n",
      "   ..., \n",
      "   [-0.44376302]\n",
      "   [-0.31773907]\n",
      "   [-0.11828604]]]]\n",
      "y_arr_validate: [[[[ 0.01409422]\n",
      "   [-0.00411432]\n",
      "   [-0.00190468]\n",
      "   ..., \n",
      "   [-0.00666123]\n",
      "   [-0.00017102]\n",
      "   [-0.00197337]]\n",
      "\n",
      "  [[-0.00783188]\n",
      "   [ 0.01333595]\n",
      "   [-0.00805861]\n",
      "   ..., \n",
      "   [-0.00838623]\n",
      "   [ 0.00097341]\n",
      "   [ 0.01067705]]\n",
      "\n",
      "  [[-0.00487761]\n",
      "   [ 0.0021541 ]\n",
      "   [ 0.01055892]\n",
      "   ..., \n",
      "   [-0.00175408]\n",
      "   [ 0.00372838]\n",
      "   [ 0.01723437]]\n",
      "\n",
      "  ..., \n",
      "  [[-0.00817108]\n",
      "   [ 0.00543034]\n",
      "   [-0.00105805]\n",
      "   ..., \n",
      "   [-0.00077615]\n",
      "   [ 0.0128486 ]\n",
      "   [-0.00788703]]\n",
      "\n",
      "  [[-0.0061416 ]\n",
      "   [ 0.01330202]\n",
      "   [ 0.0039621 ]\n",
      "   ..., \n",
      "   [-0.02177424]\n",
      "   [-0.00761711]\n",
      "   [-0.00368584]]\n",
      "\n",
      "  [[ 0.00080481]\n",
      "   [-0.00873013]\n",
      "   [-0.00553259]\n",
      "   ..., \n",
      "   [ 0.01197209]\n",
      "   [ 0.00780994]\n",
      "   [-0.01704166]]]]\n",
      "x_true_arr_validate: [[[[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   ..., \n",
      "   [ 0.]\n",
      "   [ 0.]\n",
      "   [ 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"x_arr_validate: {x_arr_validate}\")\n",
    "print(f\"y_arr_validate: {y_arr_validate}\")\n",
    "print(f\"x_true_arr_validate: {x_true_arr_validate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new_network = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_train):\n\u001b[1;32m      7\u001b[0m     x_arr, y_arr, x_true_arr \u001b[38;5;241m=\u001b[39m generate_data()\n\u001b[0;32m----> 9\u001b[0m     _, loss_training \u001b[38;5;241m=\u001b[39m \u001b[43msess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mx_0\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_arr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mx_true\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_true_arr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_arr\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Validate on shepp-logan\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     x_values_result, loss_result \u001b[38;5;241m=\u001b[39m sess\u001b[38;5;241m.\u001b[39mrun([x_values, loss],\n\u001b[1;32m     16\u001b[0m                 feed_dict\u001b[38;5;241m=\u001b[39m{x_0: x_arr_validate,\n\u001b[1;32m     17\u001b[0m                             x_true: x_true_arr_validate,\n\u001b[1;32m     18\u001b[0m                             y: y_arr_validate})\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:968\u001b[0m, in \u001b[0;36mBaseSession.run\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    965\u001b[0m run_metadata_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBuffer() \u001b[38;5;28;01mif\u001b[39;00m run_metadata \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mrun_metadata_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m run_metadata:\n\u001b[1;32m    971\u001b[0m     proto_data \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:1191\u001b[0m, in \u001b[0;36mBaseSession._run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001b[39;00m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_fetches \u001b[38;5;129;01mor\u001b[39;00m final_targets \u001b[38;5;129;01mor\u001b[39;00m (handle \u001b[38;5;129;01mand\u001b[39;00m feed_dict_tensor):\n\u001b[0;32m-> 1191\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_fetches\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mfeed_dict_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   results \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:1371\u001b[0m, in \u001b[0;36mBaseSession._do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1368\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1371\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_run_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1374\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:1378\u001b[0m, in \u001b[0;36mBaseSession._do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1377\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOpError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1380\u001b[0m     message \u001b[38;5;241m=\u001b[39m compat\u001b[38;5;241m.\u001b[39mas_text(e\u001b[38;5;241m.\u001b[39mmessage)\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:1361\u001b[0m, in \u001b[0;36mBaseSession._do_run.<locals>._run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_fn\u001b[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001b[1;32m   1359\u001b[0m   \u001b[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001b[39;00m\n\u001b[1;32m   1360\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[0;32m-> 1361\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_tf_sessionrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1362\u001b[0m \u001b[43m                                  \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/illpropinverse/lib/python3.11/site-packages/tensorflow/python/client/session.py:1454\u001b[0m, in \u001b[0;36mBaseSession._call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_tf_sessionrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, options, feed_dict, fetch_list, target_list,\n\u001b[1;32m   1453\u001b[0m                         run_metadata):\n\u001b[0;32m-> 1454\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionRun_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1455\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mfetch_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1456\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mrun_metadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "if train_new_network:\n",
    "    # Train the network\n",
    "    n_train = 100\n",
    "    validation_losses = []\n",
    "    for i in range(0, n_train):\n",
    "        x_arr, y_arr, x_true_arr = generate_data()\n",
    "\n",
    "        _, loss_training = sess.run([optimizer, loss],\n",
    "                                    feed_dict={x_0: x_arr,\n",
    "                                            x_true: x_true_arr,\n",
    "                                            y: y_arr})\n",
    "\n",
    "        # Validate on shepp-logan\n",
    "        x_values_result, loss_result = sess.run([x_values, loss],\n",
    "                    feed_dict={x_0: x_arr_validate,\n",
    "                                x_true: x_true_arr_validate,\n",
    "                                y: y_arr_validate})\n",
    "\n",
    "        # print(f'iter={i}, validation loss={loss_result}')\n",
    "        validation_losses.insert(i, loss_result)\n",
    "            # callback((space ** (n_iter + 1)).element(\n",
    "                # [xv.squeeze() for xv in x_values_result]))\n",
    "    data = {\n",
    "        'validation_losses' : validation_losses\n",
    "    }\n",
    "    df = pd.DataFrame(iter(data))\n",
    "    df.to_excel(\"validation losses.xlsx\")\n",
    "else:\n",
    "    # Validate on shepp-logan\n",
    "    x_values_result, loss_result = sess.run([x_values, loss],\n",
    "                feed_dict={x_0: x_arr_validate,\n",
    "                            x_true: x_true_arr_validate,\n",
    "                            y: y_arr_validate})\n",
    "\n",
    "    print(f'validation loss={loss_result}')\n",
    "\n",
    "    callback((space ** (n_iter + 1)).element(\n",
    "        [xv.squeeze() for xv in x_values_result]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "illpropinverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
